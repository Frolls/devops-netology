# Решение домашнего задания к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её
нужно прервать.

Вы как инженер поддержки решили произвести данную операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

**Решение**

- **напишите список операций, которые вы будете производить для остановки запроса пользователя**

Нужно убить длительную операцию, выполнив команду `db.killOp(<opId>)`, осталось только найти этот волшебный `<opId>`..

Вычислить проблемные запросы возможно, используя вызов mongo-shell типа:

```json
db.currentOp(
    { 
    "active" : true,
    "secs_running" : { "$gt" : 180 }
    }
)
```

В результате вернется ответ, который будет содержать строки типа

```json
...
{
  "inprog": [
       {
         "type" : <string>,
         "host" : <string>,
         "desc" : <string>,
         "connectionId" : <number>,
         "client" : <string>,
         "appName" : <string>,
         "clientMetadata" : <document>,
         "active" : <boolean>,
         "currentOpTime" : <string>,
         "effectiveUsers" : [
            {
               "user" : <string>,
               "db" : <string>
            }
         ],
         "opid" : <number>,
         "lsid" : {
            "id" : <UUID>,
            "uid" : <BinData>
         },
         "secs_running" : <NumberLong()>,
         "microsecs_running" : <number>,
...
```

Бинго! Нам нужно значение `opid` )

В итоге, теперь зная `opid`, выполним db.killOp(<opid>), успокоив тем самым разработчика.

- **предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB**

Чем раньше получится обнаружить проблему/потенциальную проблему, тем лучше. Поэтому нужно не стесняться пользоваться мониторингом, профилированием. Ну а дальше использовать старый добрый `explain` и разбирать что конкретно тормозит и что можно с этим поделать.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

**Решение**

Возможно, проблема в задержке, вызванной истечением срока действия ключей, т.к. большое количество ключей, истекающих в один и тот же момент, может быть источником задержки. [Вот](https://redis.io/docs/reference/optimization/latency/#latency-generated-by-expires)


## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

**Решение**

**Как вы думаете, почему это начало происходить и как локализовать проблему?**

Это сообщение об ошибке может быть вызвано [тремя вероятными причинами](https://dev.mysql.com/doc/refman/8.0/en/error-lost-connection.html):

- проблемы с подключением к сети. Следует проверить состояние сети.
- когда миллионы строк отправляются как часть одного или нескольких запросов. Можно попробовать увеличить `net_read_timeout` до 60 с или больше.
- клиент пытается установить первоначальное соединение с сервером при медленном соединении. Увеличить `connect_timeout`

Если не помогло, то можно попробовать увеличить размер `max_allowed_packet` в случае если есть большие BLOB.

**Какие пути решения данной проблемы вы можете предложить?**

Все перечисленное в предыдущем вопросе, плюс увеличить таймауты, попытаться оптисизировать запросы. Может просто не хватает индексов в таблицах..

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?


**Решение**

**Как вы думаете, что происходит?** PostgeSQL явно не хватает памяти

**Как бы вы решили данную проблему?** 

Варианты:

1. Решение "в лоб #1": отключить OOM-Killer )) `$ echo 0 > /proc/sys/vm/panic_on_oom`
1. Решение "в лоб #2": добавить памяти на сервер
1. Настроить `vm.overcommit_memory = 2` и `overcommit_ratio`. Увеличить swap, но это повлияет на эффективность БД из-за операций ввода-вывода. 
[Вот тут немного описано](https://habr.com/ru/company/southbridge/blog/464245/)
1. Может дело не только в Postgres, но и что-то другое кушает память?